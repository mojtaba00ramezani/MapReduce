{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "پیاده سازی مقاله deeplearning hand written recognition مجتبی رمضانی"
      ],
      "metadata": {
        "id": "LBo_3jm9y5hO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zTZPMsIYy5Sd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrMjL-KRB1Oy"
      },
      "source": [
        "در این مرحله پکیج ها بارگزاری می شوند پکیج های استفاده شده در پروژه شامل \n",
        "\n",
        "\n",
        "---\n",
        "tensorflow,\n",
        "numpy,\n",
        "pandas,\n",
        "multiprocessing,\n",
        "time \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiefpDUqtak3",
        "outputId": "368679e9-2c15-4c24-f3f0-2922f4b61a0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from multiprocessing import Process,Manager\n",
        "import time\n",
        "graph=tf.Graph()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHwm5S11CsP5"
      },
      "source": [
        "در این مرحله مدل CNN با وزن قبلی هت شناسایی اعداد ایجاد می گردد"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKjX0N7aui-O"
      },
      "outputs": [],
      "source": [
        "\n",
        "start_time = time.time()\n",
        "def CNN_Part(number,training_data,training_labels,validation_data,return_dict):\n",
        "\n",
        "        print (\"start\")\n",
        "        num_lables=10\n",
        "        image_size=28\n",
        "        \n",
        "        learning_rate=1e-2\n",
        "        batch_size=50\n",
        "\n",
        "        def weights(shape):\n",
        "            return tf.Variable(tf.truncated_normal(shape,stddev=0.1))\n",
        "        \n",
        "        def biases(shape):\n",
        "            return tf.Variable(tf.constant(0.1,shape=shape))\n",
        "        \n",
        "        def conv2d(data,wts):\n",
        "            return tf.nn.conv2d(data,wts,strides=[1,1,1,1],padding='SAME',use_cudnn_on_gpu=False)\n",
        "        \n",
        "        def max_pooling(value):\n",
        "            return tf.nn.max_pool(value,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
        "        \n",
        "        def accuracy(predictions, labels):\n",
        "          return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
        "                  / predictions.shape[0])\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        global graph\n",
        "        graph=tf.Graph()\n",
        "        with graph.as_default():\n",
        "        \n",
        "        \n",
        "            tf_train_data=tf.placeholder(tf.float32,shape=[batch_size,image_size*image_size])\n",
        "            tf_train_labels=tf.placeholder(tf.float32,shape=[batch_size,num_lables])\n",
        "        \n",
        "            tf_valid_data=tf.constant(validation_data)\n",
        "            tf_test_data=tf.placeholder(tf.float32,shape=[batch_size,image_size*image_size])\n",
        "            \n",
        "            \n",
        "            layer1_w=weights([5,5,1,32])\n",
        "            layer1_b=biases([32])\n",
        "        \n",
        "            layer2_w=weights([5,5,32,64])\n",
        "            layer2_b=biases([64])\n",
        "        \n",
        "            fully_w=weights([7*7*64,1024])\n",
        "            fully_b=biases([1024])\n",
        "            final_w=weights([1024,num_lables])\n",
        "            final_b=biases([num_lables])\n",
        "        \n",
        "        \n",
        "            def model(data):\n",
        "        \n",
        "     \n",
        "                image=tf.reshape(data,[-1,image_size,image_size,1])\n",
        "        \n",
        "                hidden1_conv=tf.nn.relu(conv2d(image,layer1_w)+layer1_b)\n",
        "                hidden1_pool=max_pooling(hidden1_conv)\n",
        "        \n",
        "                hidden2_conv=tf.nn.relu(conv2d(hidden1_pool,layer2_w)+layer2_b)\n",
        "                hidden2_pool=max_pooling(hidden2_conv)\n",
        "        \n",
        "                hidden2_pool_flat=tf.reshape(hidden2_pool,[-1,7*7*64])\n",
        "                hidden_fully=tf.nn.relu(tf.matmul(hidden2_pool_flat,fully_w)+fully_b)\n",
        "                \n",
        "                hidden_final=tf.nn.dropout(hidden_fully,rate=0.1)\n",
        "                \n",
        "                \n",
        "                return  tf.matmul(hidden_final,final_w)+final_b\n",
        "        \n",
        "            print (\"start2\")\n",
        "            logits=model(tf_train_data)\n",
        "            \n",
        "            loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=tf_train_labels))\n",
        "\n",
        "            optimization=tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
        "            \n",
        "            valid_predections=tf.nn.softmax(model(tf_valid_data))\n",
        "            \n",
        "            train_predections=tf.nn.softmax(logits)            \n",
        "            valid_parameter=model(tf_valid_data)\n",
        "            \n",
        "            \n",
        "           \n",
        "    \n",
        "        num_steps=100\n",
        "        \n",
        "               \n",
        "        with tf.Session(graph=graph) as session:\n",
        "            \n",
        "        \n",
        "            tf.initialize_all_variables().run()\n",
        "            print('initialized')\n",
        "        \n",
        "            counter=0\n",
        "            for step in range(num_steps):\n",
        "                if counter>len(training_data):\n",
        "                    prem=np.arange(len(training_data))\n",
        "                    np.random.shuffle(prem)\n",
        "                    training_data=training_data[prem]\n",
        "                    training_labels=training_labels[prem]\n",
        "                    counter=0\n",
        "                offset = (step * batch_size) % (training_labels.shape[0] - batch_size)\n",
        "                batch_data = training_data[offset:(offset + batch_size), :]\n",
        "                batch_labels = training_labels[offset:(offset + batch_size), :]\n",
        "        \n",
        "                feed_dict={tf_train_data:batch_data,tf_train_labels:batch_labels}\n",
        "                \n",
        "                print (\"Step\",counter)\n",
        "                _,parameter= session.run([optimization,valid_parameter], feed_dict=feed_dict)\n",
        "                \n",
        "\n",
        "                counter+=1\n",
        "\n",
        "        return_dict[number]=parameter\n",
        "        print (parameter)\n",
        "        \n",
        "        return parameter\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def splitdata(data):\n",
        "\n",
        "        data1=data[1:2000]\n",
        "        data2=data[10000:20000]\n",
        "        data3=data[20000:30000]\n",
        "        \n",
        "        images1=np.array(data1.drop('label',axis=1)).astype(np.float32)\n",
        "        images1=np.multiply(images1,1.0/255.0)\n",
        "        \n",
        "        labels1=np.array(data1.label).astype(np.float32)        \n",
        "        labels1=(np.arange(10)==labels1[:,None]).astype(np.float32)              \n",
        "        \n",
        "        images2=np.array(data2.drop('label',axis=1)).astype(np.float32)\n",
        "        images2=np.multiply(images2,1.0/255.0)\n",
        "        \n",
        "        labels2=np.array(data2.label).astype(np.float32)        \n",
        "        labels2=(np.arange(10)==labels2[:,None]).astype(np.float32)\n",
        "                       \n",
        "        images3=np.array(data3.drop('label',axis=1)).astype(np.float32)\n",
        "        images3=np.multiply(images3,1.0/255.0)\n",
        "        labels3=np.array(data3.label).astype(np.float32)        \n",
        "        labels3=(np.arange(10)==labels3[:,None]).astype(np.float32)\n",
        "       \n",
        "        training_data1=images2\n",
        "        training_labels1=labels2\n",
        "        \n",
        "        training_data2=images3\n",
        "        training_labels2=labels3\n",
        "                        \n",
        "        validation_data=images1\n",
        "        validation_labels=labels1\n",
        "        \n",
        "        \n",
        "        return (training_data1,training_labels1,training_data2,training_labels2,validation_data,validation_labels)\n",
        "\n",
        "\n",
        "def Caculate_P(someweight,validation_labels):\n",
        "        def accuracy(predictions, labels):\n",
        "          return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
        "                  / predictions.shape[0])\n",
        "        \n",
        "        with tf.Session(graph=graph) as session:\n",
        "            \n",
        "            position=tf.nn.softmax(someweight)\n",
        "            \n",
        "            position=position.eval()\n",
        "                \n",
        "            print (position )     \n",
        "                            \n",
        "            print('Validation accuracy: %.1f%%' % accuracy(position, validation_labels))              \n",
        "            \n",
        "            return position\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0S2JFn-S6TE"
      },
      "source": [
        "اجرا بدون معماری mapreduce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brNXRS-Hutif",
        "outputId": "fab6773c-b966-4386-9df4-493d1b4d165e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "111.874999\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "start\n",
            "start2\n",
            "initialized\n",
            "Step 0\n",
            "Step 1\n",
            "Step 2\n",
            "Step 3\n",
            "Step 4\n",
            "Step 5\n",
            "Step 6\n",
            "Step 7\n",
            "Step 8\n",
            "Step 9\n",
            "Step 10\n",
            "Step 11\n",
            "Step 12\n",
            "Step 13\n",
            "Step 14\n",
            "Step 15\n",
            "Step 16\n",
            "Step 17\n",
            "Step 18\n",
            "Step 19\n",
            "Step 20\n",
            "Step 21\n",
            "Step 22\n",
            "Step 23\n",
            "Step 24\n",
            "Step 25\n",
            "Step 26\n",
            "Step 27\n",
            "Step 28\n",
            "Step 29\n",
            "Step 30\n",
            "Step 31\n",
            "Step 32\n",
            "Step 33\n",
            "Step 34\n",
            "Step 35\n",
            "Step 36\n",
            "Step 37\n",
            "Step 38\n",
            "Step 39\n",
            "Step 40\n",
            "Step 41\n",
            "Step 42\n",
            "Step 43\n",
            "Step 44\n",
            "Step 45\n",
            "Step 46\n",
            "Step 47\n",
            "Step 48\n",
            "Step 49\n",
            "Step 50\n",
            "Step 51\n",
            "Step 52\n",
            "Step 53\n",
            "Step 54\n",
            "Step 55\n",
            "Step 56\n",
            "Step 57\n",
            "Step 58\n",
            "Step 59\n",
            "Step 60\n",
            "Step 61\n",
            "Step 62\n",
            "Step 63\n",
            "Step 64\n",
            "Step 65\n",
            "Step 66\n",
            "Step 67\n",
            "Step 68\n",
            "Step 69\n",
            "Step 70\n",
            "Step 71\n",
            "Step 72\n",
            "Step 73\n",
            "Step 74\n",
            "Step 75\n",
            "Step 76\n",
            "Step 77\n",
            "Step 78\n",
            "Step 79\n",
            "Step 80\n",
            "Step 81\n",
            "Step 82\n",
            "Step 83\n",
            "Step 84\n",
            "Step 85\n",
            "Step 86\n",
            "Step 87\n",
            "Step 88\n",
            "Step 89\n",
            "Step 90\n",
            "Step 91\n",
            "Step 92\n",
            "Step 93\n",
            "Step 94\n",
            "Step 95\n",
            "Step 96\n",
            "Step 97\n",
            "Step 98\n",
            "Step 99\n",
            "[[ 7.736147   -7.8991027   2.2345102  ... -4.442497    1.3243134\n",
            "  -3.6283865 ]\n",
            " [-2.1881347   7.5436945  -2.3315513  ... -1.1239115   0.52868915\n",
            "  -2.6776295 ]\n",
            " [-0.62171304 -4.336617    2.542499   ... -0.10917536 -1.8243523\n",
            "  -2.2640674 ]\n",
            " ...\n",
            " [-0.4630341  -2.7768092  -3.3635697  ...  0.2274805   1.5475819\n",
            "  -0.8245869 ]\n",
            " [-0.20273566 -5.6226983  -2.4543045  ... -4.3187966   1.9114408\n",
            "  -4.724493  ]\n",
            " [-0.24915916 -2.3462007  -0.93568933 ...  4.754028    2.6549852\n",
            "   1.7765846 ]]\n",
            "start\n",
            "start2\n",
            "initialized\n",
            "Step 0\n",
            "Step 1\n",
            "Step 2\n",
            "Step 3\n",
            "Step 4\n",
            "Step 5\n",
            "Step 6\n",
            "Step 7\n",
            "Step 8\n",
            "Step 9\n",
            "Step 10\n",
            "Step 11\n",
            "Step 12\n",
            "Step 13\n",
            "Step 14\n",
            "Step 15\n",
            "Step 16\n",
            "Step 17\n",
            "Step 18\n",
            "Step 19\n",
            "Step 20\n",
            "Step 21\n",
            "Step 22\n",
            "Step 23\n",
            "Step 24\n",
            "Step 25\n",
            "Step 26\n",
            "Step 27\n",
            "Step 28\n",
            "Step 29\n",
            "Step 30\n",
            "Step 31\n",
            "Step 32\n",
            "Step 33\n",
            "Step 34\n",
            "Step 35\n",
            "Step 36\n",
            "Step 37\n",
            "Step 38\n",
            "Step 39\n",
            "Step 40\n",
            "Step 41\n",
            "Step 42\n",
            "Step 43\n",
            "Step 44\n",
            "Step 45\n",
            "Step 46\n",
            "Step 47\n",
            "Step 48\n",
            "Step 49\n",
            "Step 50\n",
            "Step 51\n",
            "Step 52\n",
            "Step 53\n",
            "Step 54\n",
            "Step 55\n",
            "Step 56\n",
            "Step 57\n",
            "Step 58\n",
            "Step 59\n",
            "Step 60\n",
            "Step 61\n",
            "Step 62\n",
            "Step 63\n",
            "Step 64\n",
            "Step 65\n",
            "Step 66\n",
            "Step 67\n",
            "Step 68\n",
            "Step 69\n",
            "Step 70\n",
            "Step 71\n",
            "Step 72\n",
            "Step 73\n",
            "Step 74\n",
            "Step 75\n",
            "Step 76\n",
            "Step 77\n",
            "Step 78\n",
            "Step 79\n",
            "Step 80\n",
            "Step 81\n",
            "Step 82\n",
            "Step 83\n",
            "Step 84\n",
            "Step 85\n",
            "Step 86\n",
            "Step 87\n",
            "Step 88\n",
            "Step 89\n",
            "Step 90\n",
            "Step 91\n",
            "Step 92\n",
            "Step 93\n",
            "Step 94\n",
            "Step 95\n",
            "Step 96\n",
            "Step 97\n",
            "Step 98\n",
            "Step 99\n",
            "[[11.095559   -5.86659     3.2967784  ... -2.2961483  -0.04596999\n",
            "   0.13409592]\n",
            " [-0.37530732  5.0373693  -0.1902377  ...  2.112738   -0.3364569\n",
            "  -1.2754558 ]\n",
            " [ 0.7755617  -3.3387434   0.81046915 ...  0.98878276 -1.3283021\n",
            "   0.74735963]\n",
            " ...\n",
            " [-0.9646788  -3.5832675  -1.1334307  ...  0.24068543  4.1268954\n",
            "   1.5152506 ]\n",
            " [ 0.80559903 -2.7180228   2.8536506  ... -5.994724    0.93040955\n",
            "   0.46856844]\n",
            " [-3.0270684  -1.8567272  -4.233035   ...  0.86637187  0.3682102\n",
            "   4.530662  ]]\n",
            "[[9.9999833e-01 6.9683194e-15 1.6737893e-06 ... 7.8512041e-12\n",
            "  2.3805113e-08 2.0134526e-10]\n",
            " [2.6473668e-07 9.9997628e-01 2.7599657e-07 ... 9.2372975e-06\n",
            "  4.1647440e-06 6.5962936e-08]\n",
            " [1.3042348e-03 5.1900724e-07 3.1968024e-02 ... 2.6949376e-03\n",
            "  4.7792495e-05 2.4538190e-04]\n",
            " ...\n",
            " [1.9805467e-04 1.4278638e-06 9.2004811e-06 ... 1.3187273e-03\n",
            "  2.4056222e-01 1.6473453e-03]\n",
            " [9.2913404e-05 1.2131904e-08 7.5803997e-05 ... 1.6871479e-09\n",
            "  8.7188272e-04 7.2099749e-07]\n",
            " [5.7857744e-07 2.2903431e-07 8.7188674e-08 ... 4.2278282e-03\n",
            "  3.1489506e-04 8.4025525e-03]]\n",
            "Validation accuracy: 88.7%\n",
            "Total Time: 292.96030259132385\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if __name__ == '__main__': \n",
        "     time0=time.clock()\n",
        "     print (time0)\n",
        "     manager = Manager()\n",
        "     return_dict = manager.dict()\n",
        "     jobs = []\n",
        "    \n",
        "     data=pd.read_csv('drive/My Drive/train_test.csv',header=0)\n",
        "     \n",
        "     \n",
        "     dataset=splitdata(data)    \n",
        "     CNN_Part(1,dataset[0],dataset[1],dataset[4],return_dict)\n",
        "     CNN_Part(2,dataset[2],dataset[3],dataset[4],return_dict)\n",
        "\n",
        "     finalpare=return_dict.get(1)+return_dict.get(2)\n",
        "     Caculate_P(finalpare,dataset[5])\n",
        "     save=time.time() - start_time\n",
        "      \n",
        "     print (\"Total Time:\", save)\n",
        " \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "اجرا با معماری mapreduce"
      ],
      "metadata": {
        "id": "7AzycBzwykca"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5SJsPdGD9oL",
        "outputId": "a21ecce4-356c-4b2c-b754-5e493ed6c991"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "666.829977\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
            "  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "start\n",
            "start\n",
            "start2\n",
            "start2\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__': \n",
        "     time0=time.clock()\n",
        "     print (time0)\n",
        "     manager = Manager()\n",
        "     return_dict = manager.dict()\n",
        "     jobs = []\n",
        "    \n",
        "     data=pd.read_csv('drive/My Drive/train_test.csv',header=0)\n",
        "     \n",
        "     dataset=splitdata(data)\n",
        "     \n",
        "     batch1=Process(target=CNN_Part,args=(1,dataset[0],dataset[1],dataset[4],return_dict))\n",
        "     jobs.append(batch1)\n",
        "     batch1.start()\n",
        "    \n",
        "     batch2=Process(target=CNN_Part,args=(2,dataset[2],dataset[3],dataset[4],return_dict)) \n",
        "     jobs.append(batch2)\n",
        "     batch2.start()\n",
        " \n",
        "     for proc in jobs:\n",
        "        proc.join()\n",
        "      \n",
        "\n",
        "     finalpare=return_dict.get(1)+return_dict.get(2)\n",
        "\n",
        "     Caculate_P(finalpare,dataset[5])\n",
        "     \n",
        "     save=time.time() - start_time\n",
        "     \n",
        "\n",
        "     print (\"Total Time:\", save)\n",
        " "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "DeepLearning_Hand_Written_Recognition.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}